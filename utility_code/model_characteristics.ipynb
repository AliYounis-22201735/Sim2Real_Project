{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to explore key characteristics of the image-based and vector-based PPO trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8Bcx9GkQfoq"
   },
   "source": [
    "### Import Required Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dZcWCINuQfor"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from stable_baselines3 import PPO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEJsAysfQfos"
   },
   "source": [
    "### Loading Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/donkey_2/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at least 16 arguments, got 15\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/donkey_2/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at least 16 arguments, got 15\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/donkey_2/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at least 16 arguments, got 15\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/donkey_2/lib/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/donkey_2/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:751: UserWarning: You are probably loading a A2C/PPO model saved with SB3 < 1.7.0, we deactivated exact_match so you can save the model again to avoid issues in the future (see https://github.com/DLR-RM/stable-baselines3/issues/1233 for more info). Original error: Error(s) in loading state_dict for ActorCriticCnnPolicy:\n",
      "\tMissing key(s) in state_dict: \"pi_features_extractor.cnn.0.weight\", \"pi_features_extractor.cnn.0.bias\", \"pi_features_extractor.cnn.2.weight\", \"pi_features_extractor.cnn.2.bias\", \"pi_features_extractor.cnn.4.weight\", \"pi_features_extractor.cnn.4.bias\", \"pi_features_extractor.linear.0.weight\", \"pi_features_extractor.linear.0.bias\", \"vf_features_extractor.cnn.0.weight\", \"vf_features_extractor.cnn.0.bias\", \"vf_features_extractor.cnn.2.weight\", \"vf_features_extractor.cnn.2.bias\", \"vf_features_extractor.cnn.4.weight\", \"vf_features_extractor.cnn.4.bias\", \"vf_features_extractor.linear.0.weight\", \"vf_features_extractor.linear.0.bias\".  \n",
      "Note: the model should still work fine, this only a warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/donkey_2/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at least 16 arguments, got 15\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/donkey_2/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at least 16 arguments, got 15\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/donkey_2/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at least 16 arguments, got 15\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/donkey_2/lib/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image_model = PPO.load(\"image_model/image_model\")\n",
    "vector_model = PPO.load(\"vector_model/vector_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaVvGXkNQfoz"
   },
   "source": [
    "### Actor-Critic Policy Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mNjosaimQfoz",
    "outputId": "c64af8eb-3cb9-4d18-f1cd-c3251ea3904a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticCnnPolicy(\n",
       "  (features_extractor): NatureCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(15, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=3136, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): NatureCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(15, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=3136, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): NatureCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(15, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=3136, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_policy = image_model.policy\n",
    "image_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (pi_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (vf_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=470, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=470, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_policy = vector_model.policy\n",
    "vector_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action and Observation Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.  0.], 1.0, (2,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_model.action_space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.  0.], 1.0, (2,), float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_model.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (15, 84, 84), uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_model.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-inf, inf, (470,), float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_model.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of Trainable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Model Trainable Parameters: 2002531\n"
     ]
    }
   ],
   "source": [
    "print(\"Image Model Trainable Parameters:\", sum(p.numel() for p in image_policy.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakdown of Image-Based Model Trainable Parameters:\n",
      "----------------------------------------------------\n",
      "features_extractor.cnn.0: 30752\n",
      "features_extractor.cnn.2: 32832\n",
      "features_extractor.cnn.4: 36928\n",
      "features_extractor.linear.0: 1606144\n",
      "mlp_extractor.policy_net.0: 131328\n",
      "mlp_extractor.policy_net.2: 16448\n",
      "mlp_extractor.value_net.0: 131328\n",
      "mlp_extractor.value_net.2: 16448\n",
      "action_net: 130\n",
      "value_net: 65\n"
     ]
    }
   ],
   "source": [
    "print(f\"Breakdown of Image-Based Model Trainable Parameters:\\n{'-'*52}\")\n",
    "for name, module in image_model.policy.named_modules():\n",
    "    if hasattr(module, \"weight\"):\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        print(f\"{name}: {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Model Trainable Parameters: 274371\n"
     ]
    }
   ],
   "source": [
    "print(\"Vector Model Trainable Parameters:\", sum(p.numel() for p in vector_policy.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakdown of Vector-Based Model Trainable Parameters:\n",
      "-----------------------------------------------------\n",
      "mlp_extractor.policy_net.0: 120576\n",
      "mlp_extractor.policy_net.2: 16448\n",
      "mlp_extractor.value_net.0: 120576\n",
      "mlp_extractor.value_net.2: 16448\n",
      "action_net: 130\n",
      "value_net: 65\n"
     ]
    }
   ],
   "source": [
    "print(f\"Breakdown of Vector-Based Model Trainable Parameters:\\n{'-'*53}\")\n",
    "for name, module in vector_model.policy.named_modules():\n",
    "    if hasattr(module, \"weight\"):\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        print(f\"{name}: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Image Input: 105840\n"
     ]
    }
   ],
   "source": [
    "image_obs_shape = image_model.policy.observation_space.shape\n",
    "input_dim = np.prod(image_obs_shape)\n",
    "print(\"Size of Image Input:\", input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vector Input: 470\n"
     ]
    }
   ],
   "source": [
    "vector_obs_shape = vector_model.policy.observation_space.shape\n",
    "input_dim = np.prod(vector_obs_shape)\n",
    "print(\"Size of Vector Input:\", input_dim)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "WS3 Going The Distance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "donkey_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "47.6875px",
    "left": "1058px",
    "top": "147.125px",
    "width": "159.359px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
